{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d3c86f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import col, count, when, isnan, max, sum ,to_date, year,month\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14dd0f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connection details with PostgreSQL\n",
    "PSQL_SERVERNAME = \"localhost\"\n",
    "PSQL_PORTNUMBER = 5432\n",
    "PSQL_DBNAME = \"mydb\"\n",
    "PSQL_USRRNAME = \"lamdo\"\n",
    "PSQL_PASSWORD = \"lamdo1\"\n",
    "URL = f\"jdbc:postgresql://{PSQL_SERVERNAME}:{PSQL_PORTNUMBER}/{PSQL_DBNAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7541e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name_Table you want to create in the database \n",
    "TABLE_POSTGRES = \"test_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74511a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lamdo/.local/lib/python3.6/site-packages/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "# Connect SparkSession\n",
    "conf = SparkConf()\n",
    "path = \"/home/lamdo/spark-cluster/data/postgresql-42.2.22.jar\"\n",
    "conf.set(\"spark.jars\", path) \n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f40dde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(spark):\n",
    "    path = \"/home/lamdo/spark-cluster/data/data.csv\"\n",
    "    df = spark.read.option('inferSchema',True).option('header' , True).csv(path)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "158c8482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+--------+-------+---------+--------------+-------+---------+----------+\n",
      "|Direction|Year|      Date| Weekday|Country|Commodity|Transport_Mode|Measure|    Value|Cumulative|\n",
      "+---------+----+----------+--------+-------+---------+--------------+-------+---------+----------+\n",
      "|  Exports|2015|01/01/2015|Thursday|    All|      All|           All|      $|104000000| 104000000|\n",
      "|  Exports|2015|02/01/2015|  Friday|    All|      All|           All|      $| 96000000| 200000000|\n",
      "|  Exports|2015|03/01/2015|Saturday|    All|      All|           All|      $| 61000000| 262000000|\n",
      "|  Exports|2015|04/01/2015|  Sunday|    All|      All|           All|      $| 74000000| 336000000|\n",
      "|  Exports|2015|05/01/2015|  Monday|    All|      All|           All|      $|105000000| 442000000|\n",
      "+---------+----+----------+--------+-------+---------+--------------+-------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9bc1071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    # Define Schema\n",
    "    df_write = df.select('Date','Country','Commodity','Value','Cumulative')\n",
    "    df_write = df_write.withColumn(\"Date\",to_date(df_write[\"Date\"],\"dd/MM/yyyy\"))\n",
    "    df_write.printSchema()\n",
    "    # Find all data of United States about Meat and edible offal.\n",
    "    df_write = df_write.select(year(df_write[\"Date\"]).alias(\"Year\"),month(df_write[\"Date\"]).alias(\"Month\"),'*').\\\n",
    "                drop(df_write[\"Date\"]).\\\n",
    "                filter((df_write.Country ==\"United States\") & (df_write.Commodity==\"Meat and edible offal\"))\n",
    "    '''\n",
    "    #Check null:\n",
    "    df_write.select([count(when(col(c).contains('Null') | \\\n",
    "                                (col(c) == '' ) | \\\n",
    "                                col(c).isNull() | \\\n",
    "                                isnan(c), c \n",
    "                               )).alias(c)\n",
    "                        for c in df_write.columns]).show()\n",
    "    '''\n",
    "\n",
    "    # Caculator Value per month and year\n",
    "    df_write = df_write.groupBy(df_write[\"Year\"],df_write[\"Month\"]).\\\n",
    "                        agg(sum(\"Value\").alias(\"Value\"),max(\"Cumulative\").alias(\"Cumulative\")).\\\n",
    "                        orderBy(\"Year\", \"Month\")\n",
    "    df_write.show()\n",
    "    \n",
    "    \n",
    "    return(df_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eaddeac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df_write):\n",
    "    df_write.write\\\n",
    "        .format(\"jdbc\")\\\n",
    "        .option(\"url\", URL)\\\n",
    "        .option(\"dbtable\", TABLE_POSTGRES)\\\n",
    "        .option(\"user\", PSQL_USRRNAME)\\\n",
    "        .option(\"password\", PSQL_PASSWORD)\\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .save()\n",
    "    print('-------------------')\n",
    "    print('|Load Successfully|')\n",
    "    print('-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "83f1b37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Commodity: string (nullable = true)\n",
      " |-- Value: integer (nullable = true)\n",
      " |-- Cumulative: long (nullable = true)\n",
      "\n",
      "+----+-----+---------+----------+\n",
      "|Year|Month|    Value|Cumulative|\n",
      "+----+-----+---------+----------+\n",
      "|2015|    1|201027000| 204000000|\n",
      "|2015|    2|198025000| 403000000|\n",
      "|2015|    3|248034000| 650000000|\n",
      "|2015|    4|167024000| 818000000|\n",
      "|2015|    5|212032000|1028000000|\n",
      "|2015|    6|183025000|1216000000|\n",
      "|2015|    7|136018000|1353000000|\n",
      "|2015|    8|106011000|1458000000|\n",
      "|2015|    9|113009000|1571000000|\n",
      "|2015|   10| 64002000|1636000000|\n",
      "|2015|   11|137016000|1774000000|\n",
      "|2015|   12|141020000|1916000000|\n",
      "|2016|    1|154021000| 155000000|\n",
      "|2016|    2|155018000| 310000000|\n",
      "|2016|    3|177024000| 486000000|\n",
      "|2016|    4|176025000| 661000000|\n",
      "|2016|    5|197027000| 859000000|\n",
      "|2016|    6|180024000|1038000000|\n",
      "|2016|    7|108011000|1145000000|\n",
      "|2016|    8| 81009000|1226000000|\n",
      "+----+-----+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------\n",
      "|Load Successfully|\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    extract = extract_data(spark)\n",
    "    transform = transform_data(extract)\n",
    "    load_data(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4805377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
